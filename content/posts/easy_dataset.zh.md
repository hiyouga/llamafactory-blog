---
date: '2025-04-03T21:13:00+08:00'
draft: false
title: 'Easy Dataset × LLaMA Factory: 让大模型高效学习领域知识'
---

## 1 引言  

[Easy Dataset](https://github.com/ConardLi/easy-dataset) 是一个专为创建大型语言模型（LLM）微调数据集而设计的应用程序。它提供了直观的界面，用于上传特定领域的文件，智能分割内容，生成问题，并为模型微调生成高质量的训练数据。支持使用 OpenAI、DeepSeek、火山引擎等大模型 API 和 Ollama 本地模型调用。

[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory) 是一款开源低代码大模型微调框架，集成了业界最广泛使用的微调技术，支持通过 Web UI 界面零代码微调大模型，目前已经成为开源社区最热门的微调框架之一，GitHub 星标超过 6.3 万。支持全量微调、LoRA 微调、以及 SFT 和 DPO 等微调算法。

本教程使用 Easy Dataset 从五家互联网公司的公开财报构建 SFT 微调数据，并使用 LLaMA Factory 微调 Qwen2.5-3B-Instruct 模型，使微调后的模型能学习到财报数据集中的知识。

## 2 运行环境要求

- GPU 显存：大于等于 12 GB（可使用 [autodl.com](https://www.autodl.com/login?url=%2Fhome) 租用云 GPU）
- CUDA 版本：高于 11.6
- Python 版本：3.10

## 3​ ​使用 Easy Dataset 生成微调数据

### 3.1 安装 Easy Dataset

#### 方法一：使用安装包

如果操作系统为 Windows、Mac 或 ARM 架构的 Unix 系统，可以直接前往 Easy Dataset 仓库下载安装包：https://github.com/ConardLi/easy-dataset/releases/latest

#### 方法二：使用 Dockerfile

1.从 GitHub 拉取 Easy Dataset 仓库

```Bash
git clone https://github.com/ConardLi/easy-dataset.git
cd easy-dataset
```

2.构建 Docker 镜像

```Bash
docker build -t easy-dataset .
```

3.运行容器

```Bash
docker run -d \
    -p 1717:1717 \
    -v {YOUR_LOCAL_DB_PATH}:/app/local-db \
    --name easy-dataset \
    easy-dataset
```

{YOUR_LOCAL_DB_PATH} 替换为本地存数据库的目录作为 docker 运行环境下 /app/local-db 的挂载目录，启动后打开网页端 http://localhost:1717 即可使用 UI 界面的 Easy Dataset。

#### 方法三：使用 NPM 安装

1.下载 Node.js 和 pnpm

前往 Node.js 和 pnpm 官网安装环境：https://nodejs.org/en/download | https://pnpm.io/

使用以下代码检查 Node.js 版本是否高于 18.0

```Bash
node -v  # v22.14.0
```

2.从 GitHub 拉取 Easy Dataset 仓库

```Bash
git clone https://github.com/ConardLi/easy-dataset.git
cd easy-dataset
```

3.安装软件依赖

```Bash
pnpm install
```

4.启动 Easy Dataset 应用

```Bash
pnpm build
pnpm start
```

控制台如果出现以下输出，则说明启动成功。打开浏览器访问[对应网址](http://localhost:1717)，即可看到 Easy Dataset 的界面。

```Bash
> easy-dataset@1.2.3 start
> next start -p 1717

  ▲ Next.js 14.2.25
  - Local:        http://localhost:1717

 ✓ Ready in 287ms
```

### 3.2 示例数据下载

本教程准备了一批互联网公司财报作为示例数据，包含五篇国内互联网公司 2024 年二季度的财报，格式包括 txt 和 markdown。可以使用 git 命令或者直接访问[仓库链接](https://github.com/llm-factory/FinancialData-SecondQuarter-2024)下载。

```Bash
git clone https://github.com/llm-factory/FinancialData-SecondQuarter-2024.git
```

数据均为纯文本数据，如下为节选内容示例。

```
快手二季度净利润增超七成，CEO程一笑强调可灵AI商业化

8月20日，快手科技发布2024年第二季度业绩，总营收同比增长11.6%至约310亿元，经调整净利润同比增长73.7%达46.8亿元左右。该季度，快手的毛利率和经调整净利润率均达到单季新高，分别为55.3%和15.1%。值得一提的是，针对今年加码的AI相关业务，快手联合创始人、董事长兼CEO程一笑在财报后的电话会议上表示，可灵AI将寻求更多与B端合作变现的可能性，也会探索将大模型进一步运用到商业化推荐中，提升算法推荐效率。

线上营销服务贡献近六成收入，短剧日活用户破3亿

财报显示，线上营销服务、直播和其他服务（含电商）收入依然是拉动快手营收的“三驾马车”，分别占总营收的56.5%、30.0%和13.5%。线上营销服务收入由2023年同期的143亿元增加22.1%至2024年第二季度的175亿元，财报解释主要是由于优化智能营销解决方案及先进的算法，推动营销客户投放消耗增加。
```

### 3.3 微调数据生成

#### 创建项目并配置参数

1.在浏览器进入 Easy Dataset 主页后，点击**创建项目**

![image-1](https://github.com/user-attachments/assets/b27317f6-45bc-4690-a866-e76660a7a93e)

2.首先填写**项目名称**（必填），其他两项可留空，点击确认**创建项目**

![image-2](https://github.com/user-attachments/assets/13c379b8-b6fe-4afa-997b-74e63fe145dc)

3.项目创建后会跳转到**项目设置**页面，打开**模型配置**，选择数据生成时需要调用的大模型 API 接口

![image-3](https://github.com/user-attachments/assets/b30fbf51-7eb4-440a-a31c-62faf7a2e686)

4.这里以 DeepSeek 模型为例，填写模型**提供商**和**模型名称**，并填写 **API 密钥**，点击**保存**后将数据保存到本地，在右上角选择配置好的模型，这里的 **API 密钥**需要从模型提供商获取，且保证该 API 密钥可以调用模型供应商的大模型。

![image-4](https://github.com/user-attachments/assets/5a6ec6b1-cdb6-4a06-8262-289b4a7bb591)

5.打开**任务配置**页面，设置文本分割长度为最小 500 字符，最大 2000 字符。在问题生成设置中，修改为每 10 个字符生成一个问题，修改后在页面最下方**保存任务配置**

![image-5](https://github.com/user-attachments/assets/c37fcf99-3aed-4be1-a4b3-5fc17fafa1fa)

#### 处理数据文件

1.打开**文献处理**页面，选择模型

![iamge-6](https://github.com/user-attachments/assets/8e3fa835-644e-4828-9d0c-de08cc00e512)

![image-20251201142232444](https://github.com/user-attachments/assets/7180b822-502a-40c9-bb0d-a216ecc2ebec)

2.选择文件后点击**上传并处理文件**

![image-20251201142517732](https://github.com/user-attachments/assets/ad05b55a-c1c8-48a4-a595-f014ffea0484)

3.上传后会调用大模型解析文件内容并分块，耐心等待文件处理完成，示例数据通常需要 2 分钟左右

![image-20251201142612562](https://github.com/user-attachments/assets/77409acd-412d-49f7-9cfe-510edb16f563)

生成微调数据

1.待文件处理结束后，可以看到文本分割后的文本段，选择全部文本段，点击**自动提取问题**

![image-20251201143735958](https://github.com/user-attachments/assets/fa0ff774-01c9-46a0-95d9-adac010d6c50)2.点击后会调用大模型根据文本块来构建问题，耐心等待处理完成。视 API 速度，处理时间在 2 分钟左右

![image-20251201143859136](https://github.com/user-attachments/assets/a6bcae94-f0ee-4b27-b55b-cd41a9fb9daf)

3.处理完成后，打开**问题管理**页面，选择全部问题，点击**生成单轮对话数据集**，耐心等待数据生成。视 API 速度，处理时间可能在 20-40 分钟不等

![image-20251201144201600](https://github.com/user-attachments/assets/813628db-78e7-47df-a94d-a790ecfeb31d)

在后台可以看到任务正在进行，等待 2 分钟左右处理完成。

![image-20251201144253181](https://github.com/user-attachments/assets/539c8d00-4057-4dad-b8ad-4c73a1a75716)

#### 导出数据集到 LLaMA Factory

1.答案全部生成结束后，打开**数据集管理**页面，点击**导出数据集**

![image-20251201144505324](https://github.com/user-attachments/assets/893f4233-3bd5-4cce-a3c9-a232e62c045e)

2.在导出配置中选择**在** **LLaMA Factory** **中使用**，点击**更新** **LLaMA Factory** **配置**，即可在对应文件夹下生成配置文件，点击**复制**按钮可以将配置路径复制到粘贴板。

![image-20251201144717770](https://github.com/user-attachments/assets/8c0a9a41-fa27-4313-8d09-e00cea6cf29a)

3.在配置文件路径对应的文件夹中可以看到生成的数据文件，其中主要关注以下三个文件

a. dataset_info.json：LLaMA Factory 所需的数据集配置文件  
b. alpaca.json：以 Alpaca 格式组织的数据集文件  
c. sharegpt.json：以 Sharegpt 格式组织的数据集文件    

其中 alpaca 和 sharegpt 格式均可以用来微调，两个文件内容相同。

![image-20251201145409486](https://github.com/user-attachments/assets/0d6f0eae-f9b7-4533-843d-32042894369f)

## 4 使用 LLaMA Factory 微调 Qwen2.5-3B-Instruct 模型

### 4.1 安装 LLaMA Factory

1.创建实验所需的虚拟环境（可选）

```bash
conda create -n llamafactory python=3.10
```

2.从 GitHub 拉取 LLaMA Factory 仓库，安装环境依赖

```bash
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics,modelscope]"
```

3.运行 `llamafactory-cli version` 进行验证。若显示当前  LLaMA-Factory 版本，则说明安装成功

```
----------------------------------------------------------
| Welcome to LLaMA Factory, version 0.9.2                |
|                                                        |
| Project page: https://github.com/hiyouga/LLaMA-Factory |
----------------------------------------------------------
```

### 4.2 启动微调任务

1.确认 LLaMA Factory 安装完成后，运行以下指令启动 LLaMA Board

```bash
CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 llamafactory-cli webui
```

环境变量解释：

- CUDA_VISIBLE_DEVICES：指定使用的显卡序号，默认全部使用
- USE_MODELSCOPE_HUB：使用国内魔搭社区加速模型下载，默认不使用

启动成功后，在控制台可以看到以下信息，在浏览器中输入 http://localhost:7860 进入 Web UI 界面。

![image-20251201162731159](https://github.com/user-attachments/assets/a21b13fa-1661-4a3c-9fe2-8b9edbaf33ec)

2.进入 Web UI 界面后，选择模型为 Qwen2.5-3B-Instruct，模型路径可填写本地绝对路径，不填则从互联网下载

![image](https://github.com/user-attachments/assets/07b56f1b-b937-4d45-b8b3-ca3fad4c7cab)

3.将**数据路径**改为使用 Easy Dataset 导出的配置路径，选择 Alpaca 格式数据集

![image (1)](https://github.com/user-attachments/assets/cd6acb0a-8afd-4012-947f-3802950fc024)

4.为了让模型更好地学习数据知识，将**学习率**改为 1e-4，**训练轮数**提高到 8 轮。批处理大小和梯度累计则根据设备显存大小调整，在显存允许的情况下提高批处理大小有助于加速训练，一般保持批处理大小×梯度累积×显卡数量等于 32 即可

![image(2)](https://github.com/user-attachments/assets/0a062ebc-ff4c-4b54-99d9-bdae8ec1648a)

5.点击其他参数设置，将**保存间隔**设置为 50，保存更多的检查点，有助于观察模型效果随训练轮数的变化

![image(3)](https://github.com/user-attachments/assets/e0683ca8-3ece-4324-b67d-39c958ba4df4)

6.点击 LoRA 参数设置，将 **LoRA 秩**设置为 16，并把 **LoRA 缩放系数**设置为 32

![image(4)](https://github.com/user-attachments/assets/92ef2583-799a-4592-96fb-54626c7daa1e)

7.点击**开始**按钮，等待模型下载，一段时间后应能观察到训练过程的损失曲线

![image(5)](https://github.com/user-attachments/assets/50ef7abc-1aa8-4d07-8f87-448eeef37123)

8.等待模型训练完毕，视显卡性能，训练时间可能在 20-60 分钟不等

![image(6)](https://github.com/user-attachments/assets/44cebf35-d63a-40df-bcf9-3dd2147c1a98)

### 4.3 验证微调效果

1.选择**检查点路径**为刚才的输出目录，打开 **Chat** 页面，点击**加载模型**

![image(7)](https://github.com/user-attachments/assets/2625b02b-a4af-4591-9259-809ec33d528a)

2.在下方的对话框中输入问题后，点击提交与模型进行对话，经与原始数据比对发现微调后的模型回答正确

![image(8)](https://github.com/user-attachments/assets/155204fd-f374-4de5-8d12-14dfe83dac1c)

3.点击**卸载模型**将微调后的模型卸载，清空**检查点路径**，点击**加载模型**加载微调前的原始模型

![image(9)](https://github.com/user-attachments/assets/44d03466-2f45-4ad6-babd-246c601fd22d)

4.输入相同的问题与模型进行对话，发现原始模型回答错误，证明微调有效

![image(10)](https://github.com/user-attachments/assets/3c09ee9c-bd41-4c98-9c19-cca8deda0a2e)3B 模型的微调效果相对有限，此处仅用作教程演示。如果希望得到更好的结果，建议在资源充足的条件下尝试 7B/14B 模型。

欢迎大家关注 GitHub 仓库：

- Easy Dataset: https://github.com/ConardLi/easy-dataset
- LLaMA Factory: https://github.com/hiyouga/LLaMA-Factory